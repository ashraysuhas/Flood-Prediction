{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Flood Prediction using Machine Learning (Colab Version)\n",
                "\n",
                "This notebook demonstrates the process of building a machine learning model to predict floods based on weather data. \n",
                "It is optimized for Google Colab environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install necessary libraries\n",
                "!pip install pickle-mixin\n",
                "!pip install seaborn\n",
                "!pip install scikit-learn\n",
                "!pip install pandas\n",
                "!pip install openpyxl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upload Dataset\n",
                "from google.colab import files\n",
                "print(\"Please upload 'flood dataset.xlsx'\")\n",
                "uploaded = files.upload()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Dataset\n",
                "# Assuming the file is uploaded to the current directory\n",
                "data_path = 'flood dataset.xlsx'\n",
                "try:\n",
                "    df = pd.read_excel(data_path)\n",
                "    print(\"Dataset loaded successfully.\")\n",
                "    display(df.head())\n",
                "except FileNotFoundError:\n",
                "    print(\"Error: 'flood dataset.xlsx' not found. Please upload it using the cell above.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Visualization\n",
                "# Correlation Heatmap\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
                "plt.title('Correlation Heatmap')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Outlier Detection using Boxplots\n",
                "plt.figure(figsize=(15, 10))\n",
                "for i, col in enumerate(df.columns[:-1]): # Exclude target\n",
                "    plt.subplot(3, 4, i+1)\n",
                "    sns.boxplot(df[col])\n",
                "    plt.title(col)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handling Missing Values\n",
                "numeric_cols = df.select_dtypes(include=np.number).columns\n",
                "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
                "print(\"Missing values after handling:\")\n",
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Selection\n",
                "X = df[['Temp', 'Humidity', 'Cloud Cover', 'ANNUAL', 'Jan-Feb', 'Mar-May', 'Jun-Sep', 'Oct-Dec', 'avgjune', 'sub']]\n",
                "y = df['flood']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Scaling\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Building & Comparison\n",
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(),\n",
                "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
                "    \"Decision Tree\": DecisionTreeClassifier(),\n",
                "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "}\n",
                "\n",
                "best_model_name = \"\"\n",
                "best_accuracy = 0\n",
                "best_model_obj = None\n",
                "\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
                "    \n",
                "    if acc > best_accuracy:\n",
                "        best_accuracy = acc\n",
                "        best_model_name = name\n",
                "        best_model_obj = model\n",
                "\n",
                "print(f\"\\nBest Model: {best_model_name} with Accuracy: {best_accuracy:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluation of Best Model\n",
                "y_pred = best_model_obj.predict(X_test)\n",
                "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
                "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Saving the Best Model and Scaler\n",
                "with open('floods.save', 'wb') as f:\n",
                "    pickle.dump(best_model_obj, f)\n",
                "\n",
                "with open('transform.save', 'wb') as f:\n",
                "    pickle.dump(scaler, f)\n",
                "    \n",
                "print(\"Model saved as floods.save\")\n",
                "print(\"Scaler saved as transform.save\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download the saved model and scaler\n",
                "from google.colab import files\n",
                "files.download('floods.save')\n",
                "files.download('transform.save')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}